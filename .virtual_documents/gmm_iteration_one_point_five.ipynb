

















# IMPORT LIBRARIES AND QUICK INFO, IMPLEMENTATION OF FUNCTIONS

# stolen from notebook L07 and gpt stuff
# import stuff

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import silhouette_score
from sklearn.metrics import rand_score, adjusted_rand_score
from scipy import stats

def gmm_bic_score(estimator, X):
    """Callable to pass to GridSearchCV that will use the BIC score."""
    # Make it negative since GridSearchCV expects a score to maximize
    return -estimator.bic(X)

'''
quick notes for future me

the labels are broken up into 0-25, one for each letter of the alphabet

training data has 27,455 cases, test data has 7,172 cases

'''



# ESTABLISH DATA

train_data = pd.read_csv("data/sign_mnist_train.csv")
test_data = pd.read_csv("data/sign_mnist_test.csv")
true_labels = test_data['label']
train_labels = train_data['label']

print(f"train_data.shape is {train_data.shape}")
print(f"test_data.shape is {test_data.shape}")
print(f"true_labels.shape is {true_labels.shape}")
print(f"train_labels.shape is {train_labels.shape}")


# separate labels, data
gmm_pred = pd.DataFrame(columns = ['true', 'pred'])
gmm_pred['true'] = train_labels

predict_data = train_data.drop(['label'], axis=1)
true_data = test_data.drop(['label'], axis=1)


# fit data
gmm = GaussianMixture(n_components=5predict_data, random_state=42)
gmm.fit(predict_data)


# make prediction
gmm_pred['pred'] = gmm.predict(predict_data)


print(f"gmm_pred.shape is {gmm_pred.shape}")
print(f"predict_data.shape is {predict_data.shape}")
print(f"true_data.shape is {true_data.shape}")
print(f"gmm_pred.shape is {gmm_pred.shape}")
print(f"gmm_pred['true'].shape is {gmm_pred['true'].shape}")
print(f"gmm_pred['pred'].shape is {gmm_pred['pred'].shape}")


# calculate adjusted/non-adjusted rand index, silhouette coefficient, BIC, AIC
adjusted_rand = adjusted_rand_score(gmm_pred['true'], gmm_pred['pred'])
non_adjusted_rand = rand_score(gmm_pred['true'], gmm_pred['pred'])

print("Adjusted Rand Score:", adjusted_rand)
print("Non-Adjusted Rand Score:", non_adjusted_rand)





# calculate BIC
bic = gmm.bic(predict_data) # i'm too lazy to import it directly
print(bic)





# calculate AIC 
aic = gmm.aic(predict_data)
print(aic)


# calculate silhouette coefficient

# gonna be non-predicted data, then predicted data
silhouette = silhouette_score(predict_data, gmm_pred['pred'])

print(silhouette)



# testing with elbow/silhouette methods

# Initialize lists to store BIC scores and silhouette scores
bic_scores = []
silhouette_scores = []
components_range = [5, 10, 15, 25, 26]  # Range of components to try

# Iterate over different number of components
for n_components in components_range:
    # Initialize Gaussian Mixture Model
    gmm = GaussianMixture(n_components=n_components, random_state=42)
    
    # Fit the model
    gmm.fit(predict_data)
    
    # Calculate BIC score
    bic = gmm.bic(predict_data)
    bic_scores.append(bic)
    
    # Calculate silhouette score (optional)
    # Note: Silhouette score may not be applicable for high-dimensional data
    silhouette = silhouette_score(predict_data, gmm.predict(predict_data))
    silhouette_scores.append(silhouette)

# Plot the BIC scores
plt.figure(figsize=(10, 6))
plt.plot(components_range, bic_scores, marker='o', linestyle='-', color='b')
plt.xlabel('Number of Components')
plt.ylabel('BIC Score')
plt.title('BIC Score vs. Number of Components')
plt.grid(True)
plt.show()

# Plot the silhouette scores (optional)
plt.figure(figsize=(10, 6))
plt.plot(components_range, silhouette_scores, marker='o', linestyle='-', color='r')
plt.xlabel('Number of Components')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score vs. Number of Components')
plt.grid(True)
plt.show()




